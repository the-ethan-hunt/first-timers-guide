# K-Nearest Neighbors Algorithm

**KNN Algorithm** is a simple algorithm that is vastly used for both classification and regression analysis. "K" denotes the number of nearest neighbors that is considered when the object's class or value is assigned.
'K' is always a positive integer, and naturally a uneven number.

# Why KNN

1. Easy to interpret output
2. Less calculation time
3. Good predictive Power

## KNN Classification

The object is assigned with the class that is same with majority of nearest neighbors.

## KNN Regression

The object is assigned with the average of the values of k nearest neighbors.

## KNN Algorithm in simple

1. Pick a value for 'K'.
2. Calculate the distance (might be eucladian distance) of unknown case from all known cases.
3. Select the K-observations in the training data that are "nearest"to the unknown data point.
4. Predic the response of the unknown data point using the most popular response value from the K-nearest neighbors.

## Best value of K

The best choice of k depends upon the data; generally, larger values of k reduces effect of the noise on the classification, but make boundaries between classes less distinct. A good k can be selected by various heuristic techniques.

![](https://image.slidesharecdn.com/nearestneighboralgorithmzaffarahmed-13089169751858-phpapp02-110624070327-phpapp02/95/nearest-neighbor-algorithm-zaffar-ahmed-4-728.jpg?cb=1308899040)


## Further Reading:

[Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)

[AnalyticsVidhya](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering)

